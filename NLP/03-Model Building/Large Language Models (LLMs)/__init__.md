Over time, the capabilities of the Large Language Models have increased as follows:
1. LLMs as next token prediction systems.
2. LLMs as next token and masked token prediction systems.
3. LLMs as Question Answering (QA) systems.
	- These LLMs give answers based 
4. LLMs as Chatbots
	- These QA LLM systems with conversational history in short-term in-memory context
		- What is ***short-term in-memory context***? It means the the context vector is stored in the RAM. Hence, it's not persistent across sessions.
5. LLM-RAG 
	- These are LLM Chatbots access to ***external data***, in addition to their in-memory context.
	- The ***external data*** can be in the form of a 