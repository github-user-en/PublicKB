GPT-2 Paper: [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)
GPT-3 Paper: [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165)
Llama-1 Paper: [LLaMA: Open and Efficient Foundation Language Models](https://arxiv.org/pdf/2302.13971)
BitNet b1.58 Paper: [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764)